{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw10_adversarial_attack.ipynb","provenance":[{"file_id":"https://github.com/ga642381/ML2021-Spring/blob/main/HW10/HW10.ipynb","timestamp":1620982803776}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Q-n2e0BkhEKS"},"source":["# **Homework 10 - Adversarial Attack**\n","\n","Slides: https://reurl.cc/v5kXkk\n","\n","Videos:\n","\n","TA: ntu-ml-2021spring-ta@googlegroups.com"]},{"cell_type":"markdown","metadata":{"id":"9RX7iRXrhMA_"},"source":["## Enviroment & Download\n","\n","We make use of [pytorchcv](https://pypi.org/project/pytorchcv/) to obtain CIFAR-10 pretrained model, so we need to set up the enviroment first. We also need to download the data (200 images) which we want to attack."]},{"cell_type":"code","metadata":{"id":"d4Lw7urignqP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620983891071,"user_tz":-480,"elapsed":9189,"user":{"displayName":"劉德駿","photoUrl":"","userId":"10755332246774080837"}},"outputId":"68948ea0-6fee-4f3f-c7f8-30fc74702c38"},"source":["# set up environment\n","!pip install pytorchcv\n","\n","# download\n","!gdown --id 1fHi1ko7wr80wXkXpqpqpOxuYH1mClXoX -O data.zip\n","\n","# unzip\n","!unzip ./data.zip\n","!rm ./data.zip"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pytorchcv\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/74/e5dae0875679d296fa9a3833041699cee9222e2d3dd1f9ae1ded050b5672/pytorchcv-0.0.65-py2.py3-none-any.whl (527kB)\n","\r\u001b[K     |▋                               | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 18.8MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 15.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 40kB 14.4MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 61kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 71kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 81kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 92kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 102kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 112kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 122kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 133kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 143kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 153kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 163kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 174kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 184kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 194kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 204kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 215kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 225kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 235kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 245kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 256kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 266kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 276kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 286kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 296kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 307kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 317kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 327kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 337kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 348kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 358kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 368kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 378kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 389kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 399kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 409kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 419kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 430kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 440kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 450kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 460kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 471kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 481kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 491kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 501kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 512kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 522kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 532kB 8.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorchcv) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorchcv) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorchcv) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorchcv) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorchcv) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorchcv) (2.10)\n","Installing collected packages: pytorchcv\n","Successfully installed pytorchcv-0.0.65\n","Downloading...\n","From: https://drive.google.com/uc?id=1fHi1ko7wr80wXkXpqpqpOxuYH1mClXoX\n","To: /content/data.zip\n","100% 490k/490k [00:00<00:00, 71.3MB/s]\n","Archive:  ./data.zip\n","   creating: data/\n","   creating: data/deer/\n"," extracting: data/deer/deer13.png    \n"," extracting: data/deer/deer6.png     \n"," extracting: data/deer/deer11.png    \n"," extracting: data/deer/deer2.png     \n"," extracting: data/deer/deer10.png    \n"," extracting: data/deer/deer16.png    \n"," extracting: data/deer/deer9.png     \n"," extracting: data/deer/deer20.png    \n"," extracting: data/deer/deer15.png    \n"," extracting: data/deer/deer19.png    \n"," extracting: data/deer/deer5.png     \n"," extracting: data/deer/deer14.png    \n"," extracting: data/deer/deer4.png     \n"," extracting: data/deer/deer8.png     \n"," extracting: data/deer/deer12.png    \n"," extracting: data/deer/deer1.png     \n"," extracting: data/deer/deer7.png     \n"," extracting: data/deer/deer17.png    \n"," extracting: data/deer/deer18.png    \n"," extracting: data/deer/deer3.png     \n","   creating: data/horse/\n"," extracting: data/horse/horse9.png   \n"," extracting: data/horse/horse1.png   \n"," extracting: data/horse/horse16.png  \n"," extracting: data/horse/horse15.png  \n"," extracting: data/horse/horse19.png  \n"," extracting: data/horse/horse14.png  \n"," extracting: data/horse/horse10.png  \n"," extracting: data/horse/horse7.png   \n"," extracting: data/horse/horse2.png   \n"," extracting: data/horse/horse6.png   \n"," extracting: data/horse/horse20.png  \n"," extracting: data/horse/horse5.png   \n"," extracting: data/horse/horse18.png  \n"," extracting: data/horse/horse12.png  \n"," extracting: data/horse/horse13.png  \n"," extracting: data/horse/horse17.png  \n"," extracting: data/horse/horse4.png   \n"," extracting: data/horse/horse11.png  \n"," extracting: data/horse/horse8.png   \n"," extracting: data/horse/horse3.png   \n","   creating: data/ship/\n"," extracting: data/ship/ship10.png    \n"," extracting: data/ship/ship14.png    \n"," extracting: data/ship/ship9.png     \n"," extracting: data/ship/ship20.png    \n"," extracting: data/ship/ship5.png     \n"," extracting: data/ship/ship8.png     \n"," extracting: data/ship/ship19.png    \n"," extracting: data/ship/ship16.png    \n"," extracting: data/ship/ship13.png    \n"," extracting: data/ship/ship6.png     \n"," extracting: data/ship/ship17.png    \n"," extracting: data/ship/ship1.png     \n"," extracting: data/ship/ship12.png    \n"," extracting: data/ship/ship2.png     \n"," extracting: data/ship/ship3.png     \n"," extracting: data/ship/ship15.png    \n"," extracting: data/ship/ship4.png     \n"," extracting: data/ship/ship7.png     \n"," extracting: data/ship/ship11.png    \n"," extracting: data/ship/ship18.png    \n","   creating: data/frog/\n"," extracting: data/frog/frog10.png    \n"," extracting: data/frog/frog4.png     \n"," extracting: data/frog/frog5.png     \n"," extracting: data/frog/frog20.png    \n"," extracting: data/frog/frog15.png    \n"," extracting: data/frog/frog3.png     \n"," extracting: data/frog/frog1.png     \n"," extracting: data/frog/frog14.png    \n"," extracting: data/frog/frog2.png     \n"," extracting: data/frog/frog19.png    \n"," extracting: data/frog/frog7.png     \n"," extracting: data/frog/frog11.png    \n"," extracting: data/frog/frog17.png    \n"," extracting: data/frog/frog18.png    \n"," extracting: data/frog/frog12.png    \n"," extracting: data/frog/frog16.png    \n"," extracting: data/frog/frog8.png     \n"," extracting: data/frog/frog13.png    \n"," extracting: data/frog/frog6.png     \n"," extracting: data/frog/frog9.png     \n","   creating: data/airplane/\n"," extracting: data/airplane/airplane3.png  \n"," extracting: data/airplane/airplane4.png  \n"," extracting: data/airplane/airplane2.png  \n"," extracting: data/airplane/airplane9.png  \n"," extracting: data/airplane/airplane20.png  \n"," extracting: data/airplane/airplane18.png  \n"," extracting: data/airplane/airplane19.png  \n"," extracting: data/airplane/airplane10.png  \n"," extracting: data/airplane/airplane6.png  \n"," extracting: data/airplane/airplane13.png  \n"," extracting: data/airplane/airplane16.png  \n"," extracting: data/airplane/airplane14.png  \n"," extracting: data/airplane/airplane11.png  \n"," extracting: data/airplane/airplane1.png  \n"," extracting: data/airplane/airplane17.png  \n"," extracting: data/airplane/airplane7.png  \n"," extracting: data/airplane/airplane15.png  \n"," extracting: data/airplane/airplane5.png  \n"," extracting: data/airplane/airplane8.png  \n"," extracting: data/airplane/airplane12.png  \n","   creating: data/bird/\n"," extracting: data/bird/bird9.png     \n"," extracting: data/bird/bird12.png    \n"," extracting: data/bird/bird10.png    \n"," extracting: data/bird/bird11.png    \n"," extracting: data/bird/bird5.png     \n"," extracting: data/bird/bird8.png     \n"," extracting: data/bird/bird4.png     \n"," extracting: data/bird/bird3.png     \n"," extracting: data/bird/bird7.png     \n"," extracting: data/bird/bird18.png    \n"," extracting: data/bird/bird14.png    \n"," extracting: data/bird/bird13.png    \n"," extracting: data/bird/bird2.png     \n"," extracting: data/bird/bird15.png    \n"," extracting: data/bird/bird17.png    \n"," extracting: data/bird/bird19.png    \n"," extracting: data/bird/bird16.png    \n"," extracting: data/bird/bird6.png     \n"," extracting: data/bird/bird20.png    \n"," extracting: data/bird/bird1.png     \n","   creating: data/cat/\n"," extracting: data/cat/cat6.png       \n"," extracting: data/cat/cat1.png       \n"," extracting: data/cat/cat7.png       \n"," extracting: data/cat/cat19.png      \n"," extracting: data/cat/cat5.png       \n"," extracting: data/cat/cat9.png       \n"," extracting: data/cat/cat17.png      \n"," extracting: data/cat/cat2.png       \n"," extracting: data/cat/cat16.png      \n"," extracting: data/cat/cat10.png      \n"," extracting: data/cat/cat4.png       \n"," extracting: data/cat/cat18.png      \n"," extracting: data/cat/cat13.png      \n"," extracting: data/cat/cat11.png      \n"," extracting: data/cat/cat20.png      \n"," extracting: data/cat/cat15.png      \n"," extracting: data/cat/cat8.png       \n"," extracting: data/cat/cat14.png      \n"," extracting: data/cat/cat3.png       \n"," extracting: data/cat/cat12.png      \n","   creating: data/automobile/\n"," extracting: data/automobile/automobile17.png  \n"," extracting: data/automobile/automobile11.png  \n"," extracting: data/automobile/automobile5.png  \n"," extracting: data/automobile/automobile10.png  \n"," extracting: data/automobile/automobile20.png  \n"," extracting: data/automobile/automobile2.png  \n"," extracting: data/automobile/automobile6.png  \n"," extracting: data/automobile/automobile1.png  \n"," extracting: data/automobile/automobile19.png  \n"," extracting: data/automobile/automobile7.png  \n"," extracting: data/automobile/automobile16.png  \n"," extracting: data/automobile/automobile3.png  \n"," extracting: data/automobile/automobile14.png  \n"," extracting: data/automobile/automobile12.png  \n"," extracting: data/automobile/automobile9.png  \n"," extracting: data/automobile/automobile4.png  \n"," extracting: data/automobile/automobile8.png  \n"," extracting: data/automobile/automobile13.png  \n"," extracting: data/automobile/automobile18.png  \n"," extracting: data/automobile/automobile15.png  \n","   creating: data/dog/\n"," extracting: data/dog/dog9.png       \n"," extracting: data/dog/dog2.png       \n"," extracting: data/dog/dog15.png      \n"," extracting: data/dog/dog8.png       \n"," extracting: data/dog/dog3.png       \n"," extracting: data/dog/dog19.png      \n"," extracting: data/dog/dog12.png      \n"," extracting: data/dog/dog7.png       \n"," extracting: data/dog/dog17.png      \n"," extracting: data/dog/dog11.png      \n"," extracting: data/dog/dog16.png      \n"," extracting: data/dog/dog20.png      \n"," extracting: data/dog/dog4.png       \n"," extracting: data/dog/dog5.png       \n"," extracting: data/dog/dog14.png      \n"," extracting: data/dog/dog18.png      \n"," extracting: data/dog/dog10.png      \n"," extracting: data/dog/dog1.png       \n"," extracting: data/dog/dog13.png      \n"," extracting: data/dog/dog6.png       \n","   creating: data/truck/\n"," extracting: data/truck/truck1.png   \n"," extracting: data/truck/truck18.png  \n"," extracting: data/truck/truck9.png   \n"," extracting: data/truck/truck4.png   \n"," extracting: data/truck/truck14.png  \n"," extracting: data/truck/truck8.png   \n"," extracting: data/truck/truck12.png  \n"," extracting: data/truck/truck15.png  \n"," extracting: data/truck/truck2.png   \n"," extracting: data/truck/truck5.png   \n"," extracting: data/truck/truck3.png   \n"," extracting: data/truck/truck10.png  \n"," extracting: data/truck/truck17.png  \n"," extracting: data/truck/truck20.png  \n"," extracting: data/truck/truck19.png  \n"," extracting: data/truck/truck13.png  \n"," extracting: data/truck/truck7.png   \n"," extracting: data/truck/truck6.png   \n","  inflating: data/truck/truck16.png  \n"," extracting: data/truck/truck11.png  \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hkQQf0l1hbBs"},"source":["## Global Settings\n","\n","* $\\epsilon$ is fixed to be 8. But on **Data section**, we will first apply transforms on raw pixel value (0-255 scale) **by ToTensor (to 0-1 scale)** and then **Normalize (subtract mean divide std)**. $\\epsilon$ should be set to $\\frac{8}{255 * std}$ during attack.\n","\n","* Explaination (optional)\n","    * Denote the first pixel of original image as $p$, and the first pixel of adversarial image as $a$.\n","    * The $\\epsilon$ constraints tell us $\\left| p-a \\right| <= 8$.\n","    * ToTensor() can be seen as a function where $T(x) = x/255$.\n","    * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n","    * After applying ToTensor() and Normalize() on $p$ and $a$, the constraint becomes $\\left| N(T(p))-N(T(a)) \\right| = \\left| \\frac{\\frac{p}{255}-mean}{std}-\\frac{\\frac{a}{255}-mean}{std} \\right| = \\frac{1}{255 * std} \\left| p-a \\right| <= \\frac{8}{255 * std}.$\n","    * So, we should set $\\epsilon$ to be $\\frac{8}{255 * std}$ after ToTensor() and Normalize()."]},{"cell_type":"code","metadata":{"id":"ACghc_tsg2vE","executionInfo":{"status":"ok","timestamp":1620984027462,"user_tz":-480,"elapsed":15507,"user":{"displayName":"劉德駿","photoUrl":"","userId":"10755332246774080837"}}},"source":["import torch\n","import torch.nn as nn\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","batch_size = 8\n","\n","# the mean and std are the calculated statistics from cifar_10 dataset\n","cifar_10_mean = (0.491, 0.482, 0.447) # mean for the three channels of cifar_10 images\n","cifar_10_std = (0.202, 0.199, 0.201) # std for the three channels of cifar_10 images\n","\n","# convert mean and std to 3-dimensional tensors for future operations\n","mean = torch.tensor(cifar_10_mean).to(device).view(3, 1, 1)\n","std = torch.tensor(cifar_10_std).to(device).view(3, 1, 1)\n","\n","epsilon = 8/255/std\n","# TODO: iterative fgsm attack\n","# alpha (step size) can be decided by yourself\n","alpha = 0.8/255/std\n","\n","root = './data' # directory for storing benign images\n","# benign images: images which do not contain adversarial perturbations\n","# adversarial images: images which include adversarial perturbations"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lhBJBAlKherZ"},"source":["## Data\n","\n","Construct dataset and dataloader from root directory. Note that we store the filename of each image for future usage."]},{"cell_type":"code","metadata":{"id":"VXpRAHz0hkDt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620984028745,"user_tz":-480,"elapsed":1270,"user":{"displayName":"劉德駿","photoUrl":"","userId":"10755332246774080837"}},"outputId":"85925412-7924-4d08-da7d-7e25d6f22f08"},"source":["import os\n","import glob\n","import shutil\n","import numpy as np\n","from PIL import Image\n","from torchvision.transforms import transforms\n","from torch.utils.data import Dataset, DataLoader\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(cifar_10_mean, cifar_10_std)\n","])\n","\n","class AdvDataset(Dataset):\n","    def __init__(self, data_dir, transform):\n","        self.images = []\n","        self.labels = []\n","        self.names = []\n","        '''\n","        data_dir\n","        ├── class_dir\n","        │   ├── class1.png\n","        │   ├── ...\n","        │   ├── class20.png\n","        '''\n","        for i, class_dir in enumerate(sorted(glob.glob(f'{data_dir}/*'))):\n","            images = sorted(glob.glob(f'{class_dir}/*'))\n","            self.images += images\n","            self.labels += ([i] * len(images))\n","            self.names += [os.path.relpath(imgs, data_dir) for imgs in images]\n","        self.transform = transform\n","    def __getitem__(self, idx):\n","        image = self.transform(Image.open(self.images[idx]))\n","        label = self.labels[idx]\n","        return image, label\n","    def __getname__(self):\n","        return self.names\n","    def __len__(self):\n","        return len(self.images)\n","\n","adv_set = AdvDataset(root, transform=transform)\n","adv_names = adv_set.__getname__()\n","adv_loader = DataLoader(adv_set, batch_size=batch_size, shuffle=False)\n","\n","print(f'number of images = {adv_set.__len__()}')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["number of images = 200\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LnszlTsYrTQZ"},"source":["## Utils -- Benign Images Evaluation"]},{"cell_type":"code","metadata":{"id":"5c_zZLzkrceE","executionInfo":{"status":"ok","timestamp":1620984107753,"user_tz":-480,"elapsed":868,"user":{"displayName":"劉德駿","photoUrl":"","userId":"10755332246774080837"}}},"source":["# to evaluate the performance of model on benign images\n","def epoch_benign(model, loader, loss_fn):\n","    model.eval()\n","    train_acc, train_loss = 0.0, 0.0\n","    for x, y in loader:\n","        x, y = x.to(device), y.to(device)\n","        yp = model(x)\n","        loss = loss_fn(yp, y)\n","        train_acc += (yp.argmax(dim=1) == y).sum().item()\n","        train_loss += loss.item() * x.shape[0]\n","    return train_acc / len(loader.dataset), train_loss / len(loader.dataset)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_YJxK7YehqQy"},"source":["## Utils -- Attack Algorithm"]},{"cell_type":"code","metadata":{"id":"F_1wKfKyhrQW","executionInfo":{"status":"ok","timestamp":1620985433475,"user_tz":-480,"elapsed":809,"user":{"displayName":"劉德駿","photoUrl":"","userId":"10755332246774080837"}}},"source":["# perform fgsm attack\n","def fgsm(model, x, y, loss_fn, epsilon=epsilon):\n","    x_adv = x.detach().clone() # initialize x_adv as original benign image x\n","    x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n","    loss = loss_fn(model(x_adv), y) # calculate loss\n","    loss.backward() # calculate gradient\n","    # fgsm: use gradient ascent on x_adv to maximize loss\n","    x_adv = x_adv + epsilon * x_adv.grad.detach().sign()\n","    return x_adv\n","\n","# TODO: perform iterative fgsm attack\n","# set alpha as the step size in Global Settings section\n","# alpha and num_iter can be decided by yourself\n","def ifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=20):\n","    # initialize x_adv as original benign image x\n","    x_adv = x.detach().clone()\n","    # write a loop of num_iter to represent the iterative times\n","    for i in range(num_iter):\n","    # for each loop\n","        # call fgsm with (epsilon = alpha) to obtain new x_adv\n","        x_adv = fgsm(model, x_adv, y, loss_fn, alpha)\n","        # clip new x_adv back to [x-epsilon, x+epsilon]\n","        x_adv = torch.min(torch.max(x_adv, x-epsilon), x+ epsilon)\n","    # return x_adv\n","    return x_adv"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fYCEQwmcrmH6"},"source":["## Utils -- Attack\n","\n","* Recall\n","    * ToTensor() can be seen as a function where $T(x) = x/255$.\n","    * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n","\n","* Inverse function\n","    * Inverse Normalize() can be seen as a function where $N^{-1}(x) = x*std+mean$ where $mean$ and $std$ are constants.\n","    * Inverse ToTensor() can be seen as a function where $T^{-1}(x) = x*255$.\n","\n","* Special Noted\n","    * ToTensor() will also convert the image from shape (height, width, channel) to shape (channel, height, width), so we also need to transpose the shape back to original shape.\n","    * Since our dataloader samples a batch of data, what we need here is to transpose **(batch_size, channel, height, width)** back to **(batch_size, height, width, channel)** using np.transpose."]},{"cell_type":"code","metadata":{"id":"w5X_9x-7ro_w","executionInfo":{"status":"ok","timestamp":1620984407253,"user_tz":-480,"elapsed":665,"user":{"displayName":"劉德駿","photoUrl":"","userId":"10755332246774080837"}}},"source":["# perform adversarial attack and generate adversarial examples\n","def gen_adv_examples(model, loader, attack, loss_fn):\n","    model.eval()\n","    adv_names = []\n","    train_acc, train_loss = 0.0, 0.0\n","    for i, (x, y) in enumerate(loader):\n","        x, y = x.to(device), y.to(device)\n","        x_adv = attack(model, x, y, loss_fn) # obtain adversarial examples\n","        yp = model(x_adv)\n","        loss = loss_fn(yp, y)\n","        train_acc += (yp.argmax(dim=1) == y).sum().item()\n","        train_loss += loss.item() * x.shape[0]\n","        # store adversarial examples\n","        adv_ex = ((x_adv) * std + mean).clamp(0, 1) # to 0-1 scale\n","        adv_ex = (adv_ex * 255).clamp(0, 255) # 0-255 scale\n","        adv_ex = adv_ex.detach().cpu().data.numpy().round() # round to remove decimal part\n","        adv_ex = adv_ex.transpose((0, 2, 3, 1)) # transpose (bs, C, H, W) back to (bs, H, W, C)\n","        adv_examples = adv_ex if i == 0 else np.r_[adv_examples, adv_ex]\n","    return adv_examples, train_acc / len(loader.dataset), train_loss / len(loader.dataset)\n","\n","# create directory which stores adversarial examples\n","def create_dir(data_dir, adv_dir, adv_examples, adv_names):\n","    if os.path.exists(adv_dir) is not True:\n","        _ = shutil.copytree(data_dir, adv_dir)\n","    for example, name in zip(adv_examples, adv_names):\n","        im = Image.fromarray(example.astype(np.uint8)) # image pixel value should be unsigned int\n","        im.save(os.path.join(adv_dir, name))"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r_pMkmPytX3k"},"source":["## Model / Loss Function\n","\n","Model list is available [here](https://github.com/osmr/imgclsmob/blob/master/pytorch/pytorchcv/model_provider.py). Please select models which has _cifar10 suffix. Some of the models cannot be accessed/loaded. You can safely skip them since TA's model will not use those kinds of models."]},{"cell_type":"code","metadata":{"id":"jwto8xbPtYzQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620984410717,"user_tz":-480,"elapsed":2219,"user":{"displayName":"劉德駿","photoUrl":"","userId":"10755332246774080837"}},"outputId":"da141f71-90dc-4212-f324-77e44c1d7743"},"source":["from pytorchcv.model_provider import get_model as ptcv_get_model\n","\n","model = ptcv_get_model('resnet110_cifar10', pretrained=True).to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","benign_acc, benign_loss = epoch_benign(model, adv_loader, loss_fn)\n","print(f'benign_acc = {benign_acc:.5f}, benign_loss = {benign_loss:.5f}')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Downloading /root/.torch/models/resnet110_cifar10-0369-4d6ca1fc.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.163/resnet110_cifar10-0369-4d6ca1fc.pth.zip...\n","benign_acc = 0.95000, benign_loss = 0.22678\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uslb7GPchtMI"},"source":["## FGSM"]},{"cell_type":"code","metadata":{"id":"wQwPTVUIhuTS"},"source":["adv_examples, fgsm_acc, fgsm_loss = gen_adv_examples(model, adv_loader, fgsm, loss_fn)\n","print(f'fgsm_acc = {fgsm_acc:.5f}, fgsm_loss = {fgsm_loss:.5f}')\n","\n","create_dir(root, 'fgsm', adv_examples, adv_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WXw6p0A6shZm"},"source":["## I-FGSM"]},{"cell_type":"code","metadata":{"id":"fUEsT06Iskt2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620985450176,"user_tz":-480,"elapsed":13772,"user":{"displayName":"劉德駿","photoUrl":"","userId":"10755332246774080837"}},"outputId":"a0248e0a-7474-41d2-9240-a15b6401550d"},"source":["# TODO: iterative fgsm attack\n","adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(model, adv_loader, ifgsm, loss_fn)\n","print(f'ifgsm_acc = {ifgsm_acc:.5f}, ifgsm_loss = {ifgsm_loss:.5f}')\n","\n","create_dir(root, 'ifgsm', adv_examples, adv_names)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["ifgsm_acc = 0.01000, ifgsm_loss = 17.33047\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DQ-nYkkYexEE"},"source":["## Compress the images"]},{"cell_type":"code","metadata":{"id":"ItRo_S0M264N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620985581454,"user_tz":-480,"elapsed":2433,"user":{"displayName":"劉德駿","photoUrl":"","userId":"10755332246774080837"}},"outputId":"a59682fe-2a92-4a08-b67c-c035847967ae"},"source":["# %cd fgsm\n","# !tar zcvf ../fgsm.tgz *\n","# %cd ..\n","\n","%cd ifgsm\n","!tar zcvf ../ifgsm.tgz *\n","%cd .."],"execution_count":15,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: 'fgsm'\n","/content\n","data/\n","data/bird/\n","data/bird/bird7.png\n","data/bird/bird8.png\n","data/bird/bird1.png\n","data/bird/bird3.png\n","data/bird/bird16.png\n","data/bird/bird6.png\n","data/bird/bird14.png\n","data/bird/bird13.png\n","data/bird/bird5.png\n","data/bird/bird2.png\n","data/bird/bird20.png\n","data/bird/bird17.png\n","data/bird/bird19.png\n","data/bird/bird4.png\n","data/bird/bird18.png\n","data/bird/bird11.png\n","data/bird/bird12.png\n","data/bird/bird9.png\n","data/bird/bird15.png\n","data/bird/bird10.png\n","data/ship/\n","data/ship/ship2.png\n","data/ship/ship16.png\n","data/ship/ship20.png\n","data/ship/ship13.png\n","data/ship/ship8.png\n","data/ship/ship9.png\n","data/ship/ship5.png\n","data/ship/ship19.png\n","data/ship/ship4.png\n","data/ship/ship1.png\n","data/ship/ship7.png\n","data/ship/ship6.png\n","data/ship/ship15.png\n","data/ship/ship17.png\n","data/ship/ship11.png\n","data/ship/ship18.png\n","data/ship/ship3.png\n","data/ship/ship14.png\n","data/ship/ship10.png\n","data/ship/ship12.png\n","data/airplane/\n","data/airplane/airplane7.png\n","data/airplane/airplane11.png\n","data/airplane/airplane19.png\n","data/airplane/airplane18.png\n","data/airplane/airplane16.png\n","data/airplane/airplane4.png\n","data/airplane/airplane12.png\n","data/airplane/airplane3.png\n","data/airplane/airplane13.png\n","data/airplane/airplane10.png\n","data/airplane/airplane15.png\n","data/airplane/airplane2.png\n","data/airplane/airplane1.png\n","data/airplane/airplane14.png\n","data/airplane/airplane5.png\n","data/airplane/airplane9.png\n","data/airplane/airplane8.png\n","data/airplane/airplane20.png\n","data/airplane/airplane6.png\n","data/airplane/airplane17.png\n","data/truck/\n","data/truck/truck6.png\n","data/truck/truck20.png\n","data/truck/truck10.png\n","data/truck/truck18.png\n","data/truck/truck5.png\n","data/truck/truck14.png\n","data/truck/truck9.png\n","data/truck/truck13.png\n","data/truck/truck1.png\n","data/truck/truck11.png\n","data/truck/truck3.png\n","data/truck/truck15.png\n","data/truck/truck19.png\n","data/truck/truck8.png\n","data/truck/truck12.png\n","data/truck/truck17.png\n","data/truck/truck16.png\n","data/truck/truck4.png\n","data/truck/truck7.png\n","data/truck/truck2.png\n","data/frog/\n","data/frog/frog3.png\n","data/frog/frog15.png\n","data/frog/frog8.png\n","data/frog/frog2.png\n","data/frog/frog7.png\n","data/frog/frog4.png\n","data/frog/frog17.png\n","data/frog/frog20.png\n","data/frog/frog19.png\n","data/frog/frog10.png\n","data/frog/frog1.png\n","data/frog/frog14.png\n","data/frog/frog5.png\n","data/frog/frog12.png\n","data/frog/frog9.png\n","data/frog/frog6.png\n","data/frog/frog16.png\n","data/frog/frog13.png\n","data/frog/frog18.png\n","data/frog/frog11.png\n","data/deer/\n","data/deer/deer3.png\n","data/deer/deer2.png\n","data/deer/deer10.png\n","data/deer/deer6.png\n","data/deer/deer20.png\n","data/deer/deer11.png\n","data/deer/deer12.png\n","data/deer/deer5.png\n","data/deer/deer19.png\n","data/deer/deer15.png\n","data/deer/deer4.png\n","data/deer/deer16.png\n","data/deer/deer13.png\n","data/deer/deer8.png\n","data/deer/deer1.png\n","data/deer/deer14.png\n","data/deer/deer7.png\n","data/deer/deer9.png\n","data/deer/deer18.png\n","data/deer/deer17.png\n","data/horse/\n","data/horse/horse9.png\n","data/horse/horse15.png\n","data/horse/horse16.png\n","data/horse/horse2.png\n","data/horse/horse14.png\n","data/horse/horse12.png\n","data/horse/horse13.png\n","data/horse/horse10.png\n","data/horse/horse3.png\n","data/horse/horse18.png\n","data/horse/horse8.png\n","data/horse/horse17.png\n","data/horse/horse7.png\n","data/horse/horse4.png\n","data/horse/horse1.png\n","data/horse/horse5.png\n","data/horse/horse6.png\n","data/horse/horse20.png\n","data/horse/horse11.png\n","data/horse/horse19.png\n","data/automobile/\n","data/automobile/automobile17.png\n","data/automobile/automobile5.png\n","data/automobile/automobile4.png\n","data/automobile/automobile9.png\n","data/automobile/automobile1.png\n","data/automobile/automobile14.png\n","data/automobile/automobile18.png\n","data/automobile/automobile7.png\n","data/automobile/automobile10.png\n","data/automobile/automobile15.png\n","data/automobile/automobile16.png\n","data/automobile/automobile19.png\n","data/automobile/automobile12.png\n","data/automobile/automobile13.png\n","data/automobile/automobile6.png\n","data/automobile/automobile20.png\n","data/automobile/automobile3.png\n","data/automobile/automobile2.png\n","data/automobile/automobile8.png\n","data/automobile/automobile11.png\n","data/cat/\n","data/cat/cat6.png\n","data/cat/cat14.png\n","data/cat/cat12.png\n","data/cat/cat5.png\n","data/cat/cat15.png\n","data/cat/cat11.png\n","data/cat/cat3.png\n","data/cat/cat17.png\n","data/cat/cat20.png\n","data/cat/cat18.png\n","data/cat/cat10.png\n","data/cat/cat4.png\n","data/cat/cat7.png\n","data/cat/cat9.png\n","data/cat/cat13.png\n","data/cat/cat19.png\n","data/cat/cat8.png\n","data/cat/cat2.png\n","data/cat/cat1.png\n","data/cat/cat16.png\n","data/dog/\n","data/dog/dog14.png\n","data/dog/dog13.png\n","data/dog/dog20.png\n","data/dog/dog8.png\n","data/dog/dog6.png\n","data/dog/dog2.png\n","data/dog/dog1.png\n","data/dog/dog15.png\n","data/dog/dog11.png\n","data/dog/dog7.png\n","data/dog/dog17.png\n","data/dog/dog4.png\n","data/dog/dog12.png\n","data/dog/dog10.png\n","data/dog/dog16.png\n","data/dog/dog3.png\n","data/dog/dog19.png\n","data/dog/dog9.png\n","data/dog/dog5.png\n","data/dog/dog18.png\n","ifgsm/\n","ifgsm/bird/\n","ifgsm/bird/bird7.png\n","ifgsm/bird/bird8.png\n","ifgsm/bird/bird1.png\n","ifgsm/bird/bird3.png\n","ifgsm/bird/bird16.png\n","ifgsm/bird/bird6.png\n","ifgsm/bird/bird14.png\n","ifgsm/bird/bird13.png\n","ifgsm/bird/bird5.png\n","ifgsm/bird/bird2.png\n","ifgsm/bird/bird20.png\n","ifgsm/bird/bird17.png\n","ifgsm/bird/bird19.png\n","ifgsm/bird/bird4.png\n","ifgsm/bird/bird18.png\n","ifgsm/bird/bird11.png\n","ifgsm/bird/bird12.png\n","ifgsm/bird/bird9.png\n","ifgsm/bird/bird15.png\n","ifgsm/bird/bird10.png\n","ifgsm/ship/\n","ifgsm/ship/ship2.png\n","ifgsm/ship/ship16.png\n","ifgsm/ship/ship20.png\n","ifgsm/ship/ship13.png\n","ifgsm/ship/ship8.png\n","ifgsm/ship/ship9.png\n","ifgsm/ship/ship5.png\n","ifgsm/ship/ship19.png\n","ifgsm/ship/ship4.png\n","ifgsm/ship/ship1.png\n","ifgsm/ship/ship7.png\n","ifgsm/ship/ship6.png\n","ifgsm/ship/ship15.png\n","ifgsm/ship/ship17.png\n","ifgsm/ship/ship11.png\n","ifgsm/ship/ship18.png\n","ifgsm/ship/ship3.png\n","ifgsm/ship/ship14.png\n","ifgsm/ship/ship10.png\n","ifgsm/ship/ship12.png\n","ifgsm/airplane/\n","ifgsm/airplane/airplane7.png\n","ifgsm/airplane/airplane11.png\n","ifgsm/airplane/airplane19.png\n","ifgsm/airplane/airplane18.png\n","ifgsm/airplane/airplane16.png\n","ifgsm/airplane/airplane4.png\n","ifgsm/airplane/airplane12.png\n","ifgsm/airplane/airplane3.png\n","ifgsm/airplane/airplane13.png\n","ifgsm/airplane/airplane10.png\n","ifgsm/airplane/airplane15.png\n","ifgsm/airplane/airplane2.png\n","ifgsm/airplane/airplane1.png\n","ifgsm/airplane/airplane14.png\n","ifgsm/airplane/airplane5.png\n","ifgsm/airplane/airplane9.png\n","ifgsm/airplane/airplane8.png\n","ifgsm/airplane/airplane20.png\n","ifgsm/airplane/airplane6.png\n","ifgsm/airplane/airplane17.png\n","ifgsm/truck/\n","ifgsm/truck/truck6.png\n","ifgsm/truck/truck20.png\n","ifgsm/truck/truck10.png\n","ifgsm/truck/truck18.png\n","ifgsm/truck/truck5.png\n","ifgsm/truck/truck14.png\n","ifgsm/truck/truck9.png\n","ifgsm/truck/truck13.png\n","ifgsm/truck/truck1.png\n","ifgsm/truck/truck11.png\n","ifgsm/truck/truck3.png\n","ifgsm/truck/truck15.png\n","ifgsm/truck/truck19.png\n","ifgsm/truck/truck8.png\n","ifgsm/truck/truck12.png\n","ifgsm/truck/truck17.png\n","ifgsm/truck/truck16.png\n","ifgsm/truck/truck4.png\n","ifgsm/truck/truck7.png\n","ifgsm/truck/truck2.png\n","ifgsm/frog/\n","ifgsm/frog/frog3.png\n","ifgsm/frog/frog15.png\n","ifgsm/frog/frog8.png\n","ifgsm/frog/frog2.png\n","ifgsm/frog/frog7.png\n","ifgsm/frog/frog4.png\n","ifgsm/frog/frog17.png\n","ifgsm/frog/frog20.png\n","ifgsm/frog/frog19.png\n","ifgsm/frog/frog10.png\n","ifgsm/frog/frog1.png\n","ifgsm/frog/frog14.png\n","ifgsm/frog/frog5.png\n","ifgsm/frog/frog12.png\n","ifgsm/frog/frog9.png\n","ifgsm/frog/frog6.png\n","ifgsm/frog/frog16.png\n","ifgsm/frog/frog13.png\n","ifgsm/frog/frog18.png\n","ifgsm/frog/frog11.png\n","ifgsm/deer/\n","ifgsm/deer/deer3.png\n","ifgsm/deer/deer2.png\n","ifgsm/deer/deer10.png\n","ifgsm/deer/deer6.png\n","ifgsm/deer/deer20.png\n","ifgsm/deer/deer11.png\n","ifgsm/deer/deer12.png\n","ifgsm/deer/deer5.png\n","ifgsm/deer/deer19.png\n","ifgsm/deer/deer15.png\n","ifgsm/deer/deer4.png\n","ifgsm/deer/deer16.png\n","ifgsm/deer/deer13.png\n","ifgsm/deer/deer8.png\n","ifgsm/deer/deer1.png\n","ifgsm/deer/deer14.png\n","ifgsm/deer/deer7.png\n","ifgsm/deer/deer9.png\n","ifgsm/deer/deer18.png\n","ifgsm/deer/deer17.png\n","ifgsm/horse/\n","ifgsm/horse/horse9.png\n","ifgsm/horse/horse15.png\n","ifgsm/horse/horse16.png\n","ifgsm/horse/horse2.png\n","ifgsm/horse/horse14.png\n","ifgsm/horse/horse12.png\n","ifgsm/horse/horse13.png\n","ifgsm/horse/horse10.png\n","ifgsm/horse/horse3.png\n","ifgsm/horse/horse18.png\n","ifgsm/horse/horse8.png\n","ifgsm/horse/horse17.png\n","ifgsm/horse/horse7.png\n","ifgsm/horse/horse4.png\n","ifgsm/horse/horse1.png\n","ifgsm/horse/horse5.png\n","ifgsm/horse/horse6.png\n","ifgsm/horse/horse20.png\n","ifgsm/horse/horse11.png\n","ifgsm/horse/horse19.png\n","ifgsm/automobile/\n","ifgsm/automobile/automobile17.png\n","ifgsm/automobile/automobile5.png\n","ifgsm/automobile/automobile4.png\n","ifgsm/automobile/automobile9.png\n","ifgsm/automobile/automobile1.png\n","ifgsm/automobile/automobile14.png\n","ifgsm/automobile/automobile18.png\n","ifgsm/automobile/automobile7.png\n","ifgsm/automobile/automobile10.png\n","ifgsm/automobile/automobile15.png\n","ifgsm/automobile/automobile16.png\n","ifgsm/automobile/automobile19.png\n","ifgsm/automobile/automobile12.png\n","ifgsm/automobile/automobile13.png\n","ifgsm/automobile/automobile6.png\n","ifgsm/automobile/automobile20.png\n","ifgsm/automobile/automobile3.png\n","ifgsm/automobile/automobile2.png\n","ifgsm/automobile/automobile8.png\n","ifgsm/automobile/automobile11.png\n","ifgsm/cat/\n","ifgsm/cat/cat6.png\n","ifgsm/cat/cat14.png\n","ifgsm/cat/cat12.png\n","ifgsm/cat/cat5.png\n","ifgsm/cat/cat15.png\n","ifgsm/cat/cat11.png\n","ifgsm/cat/cat3.png\n","ifgsm/cat/cat17.png\n","ifgsm/cat/cat20.png\n","ifgsm/cat/cat18.png\n","ifgsm/cat/cat10.png\n","ifgsm/cat/cat4.png\n","ifgsm/cat/cat7.png\n","ifgsm/cat/cat9.png\n","ifgsm/cat/cat13.png\n","ifgsm/cat/cat19.png\n","ifgsm/cat/cat8.png\n","ifgsm/cat/cat2.png\n","ifgsm/cat/cat1.png\n","ifgsm/cat/cat16.png\n","ifgsm/dog/\n","ifgsm/dog/dog14.png\n","ifgsm/dog/dog13.png\n","ifgsm/dog/dog20.png\n","ifgsm/dog/dog8.png\n","ifgsm/dog/dog6.png\n","ifgsm/dog/dog2.png\n","ifgsm/dog/dog1.png\n","ifgsm/dog/dog15.png\n","ifgsm/dog/dog11.png\n","ifgsm/dog/dog7.png\n","ifgsm/dog/dog17.png\n","ifgsm/dog/dog4.png\n","ifgsm/dog/dog12.png\n","ifgsm/dog/dog10.png\n","ifgsm/dog/dog16.png\n","ifgsm/dog/dog3.png\n","ifgsm/dog/dog19.png\n","ifgsm/dog/dog9.png\n","ifgsm/dog/dog5.png\n","ifgsm/dog/dog18.png\n","ifgsm.tgz\n","sample_data/\n","sample_data/anscombe.json\n","sample_data/README.md\n","sample_data/mnist_train_small.csv\n","sample_data/california_housing_train.csv\n","sample_data/mnist_test.csv\n","sample_data/california_housing_test.csv\n","/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0FM_S886kFd8"},"source":["## Visualization"]},{"cell_type":"code","metadata":{"id":"2FCuE2njkH1O","colab":{"base_uri":"https://localhost:8080/","height":485},"executionInfo":{"status":"error","timestamp":1620986172056,"user_tz":-480,"elapsed":684,"user":{"displayName":"劉德駿","photoUrl":"","userId":"10755332246774080837"}},"outputId":"f92ba5d2-e1fb-4a52-8e42-5cdf2cb0c284"},"source":["import matplotlib.pyplot as plt\n","\n","classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","plt.figure(figsize=(10, 20))\n","cnt = 0\n","for i, cls_name in enumerate(classes):\n","    path = f'{cls_name}/{cls_name}1.png'\n","    # benign image\n","    cnt += 1\n","    plt.subplot(len(classes), 4, cnt)\n","    im = Image.open(f'./data/{path}')\n","    logit = model(transform(im).unsqueeze(0).to(device))[0]\n","    predict = logit.argmax(-1).item()\n","    prob = logit.softmax(-1)[predict].item()\n","    plt.title(f'benign: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n","    plt.axis('off')\n","    plt.imshow(np.array(im))\n","    # adversarial image\n","    cnt += 1\n","    plt.subplot(len(classes), 4, cnt)\n","    im = Image.open(f'./ifgsm/{path}')\n","    logit = model(transform(im).unsqueeze(0).to(device))[0]\n","    predict = logit.argmax(-1).item()\n","    prob = logit.softmax(-1)[predict].item()\n","    plt.title(f'adversarial: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n","    plt.axis('off')\n","    plt.imshow(np.array(im))\n","plt.tight_layout()\n","plt.show()"],"execution_count":19,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-d625c5f00af2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./data/{path}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/airplane/airplane1.png'"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x1440 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}